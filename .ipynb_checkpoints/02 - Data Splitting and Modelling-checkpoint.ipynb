{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code used in splitting and modelling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inlinedf.head(2)\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading main dataset from CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_score</th>\n",
       "      <th>votes</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aldehydic</th>\n",
       "      <th>almond</th>\n",
       "      <th>amber</th>\n",
       "      <th>animalic</th>\n",
       "      <th>anis</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>aromatic</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow floral</th>\n",
       "      <th>longevity</th>\n",
       "      <th>sillage</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>autumn</th>\n",
       "      <th>winter</th>\n",
       "      <th>gender_man</th>\n",
       "      <th>gender_unisex</th>\n",
       "      <th>gender_women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_score  votes  alcohol  aldehydic  almond  amber  animalic  anis  \\\n",
       "0           4.1   22.0      0.0        0.0     0.0    0.0       0.0   0.0   \n",
       "1           4.0   24.0      0.0        0.0     0.0    0.0       0.0   0.0   \n",
       "\n",
       "   aquatic  aromatic  ...  yellow floral  longevity  sillage  spring  summer  \\\n",
       "0      0.0       0.0  ...            0.0       3.50     2.40    0.11    0.11   \n",
       "1      0.0       0.0  ...            0.0       3.83     2.12    0.37    0.16   \n",
       "\n",
       "   autumn  winter  gender_man  gender_unisex  gender_women  \n",
       "0    0.44    0.33         0.0            0.0           1.0  \n",
       "1    0.16    0.32         0.0            0.0           1.0  \n",
       "\n",
       "[2 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting my data in 'X' and 'y' datasets:\n",
    "\n",
    "'X' dataset contains all features.\n",
    "\n",
    "In 'y' dataset is a dependent variable = 'rationg_score'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating_score', axis = 1)  #independent variables\n",
    "y = df[['rating_score']] #dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting my data in train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My training set is:  (14948, 86)\n",
      "My test set is:  (3737, 86)\n",
      "My training dependent variable is:  (14948, 1)\n",
      "My test dependent variable is:  (3737, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"My training set is: \", X_train.shape)\n",
    "print(\"My test set is: \", X_test.shape)\n",
    "print(\"My training dependent variable is: \", y_train.shape)\n",
    "print(\"My test dependent variable is: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting my train data in train and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f, X_validation, y_train_f, y_validation = train_test_split(X_train, y_train, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My final training set is:  (11958, 86)\n",
      "My validation set is:  (2990, 86)\n",
      "My training dependent variable is:  (11958, 1)\n",
      "My test dependent variable is:  (2990, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"My final training set is: \", X_train_f.shape)\n",
    "print(\"My validation set is: \", X_validation.shape)\n",
    "print(\"My training dependent variable is: \", y_train_f.shape)\n",
    "print(\"My test dependent variable is: \", y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All subsets are big enough to do validation using Train Test Split Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other models, I'm going to run Lasso Regression Model, so my data needs to be in the same scale.\n",
    "\n",
    "Scalling three columns: 'votes','longevity','sillage' using MinMaxScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "X_train_f[['votes','longevity','sillage']] = mms.fit_transform(X_train_f[['votes','longevity','sillage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "X_validation[['votes','longevity','sillage']] = mms.transform(X_validation[['votes','longevity','sillage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/Users/kalinazeligowska/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "X_test[['votes','longevity','sillage']] = mms.transform(X_test[['votes','longevity','sillage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all features are in range 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I run statistical models to find best method to predict 'rating_score' value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating on the Trainig Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train a linear regeression model as my baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train_f, y_train_f) \n",
    "\n",
    "#parameters = lin_reg.coef_   # -> shape: (1,86)\n",
    "#intercept = lin_reg.intercept_ # -> (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set: 0.09293191697928027\n",
      "R^2 for validation set: -2.8899773933717357e+19\n"
     ]
    }
   ],
   "source": [
    "print(f'R^2 for training set: {lin_reg.score(X_train_f, y_train_f)}')\n",
    "print(f'R^2 for validation set: {lin_reg.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 value for a basic linear regression is very, very low. \n",
    "\n",
    "It can mean that the data doesn't suit for linear regression model. \n",
    "\n",
    "In next steps I try to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to get better scores using Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set: 0.0\n",
      "R^2 for validation set: -1.5286184418261684e-05\n"
     ]
    }
   ],
   "source": [
    "print(f'R^2 for training set: {lasso.score(X_train_f, y_train_f)}')\n",
    "print(f'R^2 for validation set: {lasso.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 values are still very low. \n",
    "\n",
    "The performance of Lasso Regression in even worse then the performance of Baseline model.\n",
    "\n",
    "Improving results using GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.07843873934437766\n",
      "Best Params:  {'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "# find optimal alpha with grid search\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train_f, y_train_f)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set: 0.08323895305637352\n",
      "R^2 for validation set: 0.08133919142865054\n"
     ]
    }
   ],
   "source": [
    "print(f'R^2 for training set: {lasso.score(X_train_f, y_train_f)}')\n",
    "print(f'R^2 for validation set: {lasso.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using GridSearchCV, R^2 values are higher, but still not enough to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to get better results using Ridge Regression and repeating these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set: 0.09425871348061476\n",
      "R^2 for validation set: 0.07988939184365762\n"
     ]
    }
   ],
   "source": [
    "print(f'R^2 for training set: {ridge.score(X_train_f, y_train_f)}')\n",
    "print(f'R^2 for validation set: {ridge.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.08089376329529138\n",
      "Best Params:  {'alpha': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# finding optimal alpha with grid search\n",
    "\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 20, 30, 40, 50, 100, 1000]\n",
    "param_grid = dict(alpha=alpha)\n",
    "\n",
    "grid = GridSearchCV(estimator=ridge, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train_f, y_train_f)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=20, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set: 0.09068855368382034\n",
      "R^2 for validation set: 0.0820614358251387\n"
     ]
    }
   ],
   "source": [
    "print(f'R^2 for training set: {ridge.score(X_train_f, y_train_f)}')\n",
    "print(f'R^2 for validation set: {ridge.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using GridSearchCV, R^2 values are higher, but also still not enough to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparition of Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Linear Regression R^2 for training set: 0.09293191697928027\n",
      "Basic Linear Regression R^2 for validation set: -2.8899773933717357e+19\n",
      "\n",
      "Lasso R^2 for training set: 0.08323895305637352\n",
      "Lasso R^2 for validation set: 0.08133919142865054\n",
      "\n",
      "Ridge R^2 for training set: 0.09068855368382034\n",
      "Ridge R^2 for validation set: 0.0820614358251387\n"
     ]
    }
   ],
   "source": [
    "print(f'Basic Linear Regression R^2 for training set: {lin_reg.score(X_train_f, y_train_f)}')\n",
    "print(f'Basic Linear Regression R^2 for validation set: {lin_reg.score(X_validation, y_validation)}')\n",
    "\n",
    "print(f'\\nLasso R^2 for training set: {lasso.score(X_train_f, y_train_f)}')\n",
    "print(f'Lasso R^2 for validation set: {lasso.score(X_validation, y_validation)}')\n",
    "\n",
    "print(f'\\nRidge R^2 for training set: {ridge.score(X_train_f, y_train_f)}')\n",
    "print(f'Ridge R^2 for validation set: {ridge.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From comparing the r^2 values of the test and train data sets it was found that Ridge regression performed best. All are very, very low, it's not what I expected but let's try to explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge R^2 for training set: 0.09068855368382034\n",
      "Ridge R^2 for validation set: 0.0820614358251387\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nRidge R^2 for training set: {ridge.score(X_train_f, y_train_f)}')\n",
    "print(f'Ridge R^2 for validation set: {ridge.score(X_validation, y_validation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 value explains only about 9% of training set and 8% of validation set.\n",
    "\n",
    "It means that a set of independent variables, in this form, for linear regression models, in not enough to predict dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final check on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r^2: 0.09268805541546654 \n",
      "Test MSE: 0.3590187092613027\n"
     ]
    }
   ],
   "source": [
    "test_r_squared = ridge.score(X_test, y_test)\n",
    "\n",
    "y_pred_test = ridge.predict(X_test)\n",
    "test_mse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f'Test r^2: {test_r_squared} \\nTest MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the R^2, MSE, MAE of final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial R-Squared value for the ridge model is: 0.0907\n",
      "The Mean Squared Error value for the ridge model is: 0.1381\n",
      "The Mean Absolute Error value for the ridge model is: 0.284\n"
     ]
    }
   ],
   "source": [
    "initial_score_r = ridge.score(X_train_f, y_train_f)\n",
    "print('The initial R-Squared value for the ridge model is:', initial_score_r.round(4))\n",
    "\n",
    "X_train_f_preidct_ridge = ridge.predict(X_train_f)\n",
    "\n",
    "mse = mean_squared_error(y_train_f, X_train_f_preidct_ridge)\n",
    "print('The Mean Squared Error value for the ridge model is:', mse.round(4))\n",
    "\n",
    "mae = mean_absolute_error(y_train_f, X_train_f_preidct_ridge)\n",
    "print('The Mean Absolute Error value for the ridge model is:', mae.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09268805541546654"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final model intialisation\n",
    "\n",
    "final_model_ridge = Ridge(20)\n",
    "final_model = final_model_ridge.fit(X_train_f, y_train_f)\n",
    "ridge.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Possible improvements and future work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data proved to be difficult to understand. \n",
    "My starting idea for building linear regression model wasn't correct.\n",
    "\n",
    "I assume that next work on feature engineering can be good step to extend the project.\n",
    "\n",
    "My plan is combine some of features into groups to discrease number of independent variables and add some new to improve performance of the model.\n",
    "\n",
    "Examples of new information:\n",
    "\n",
    "* perfume's price\n",
    "* common capacity \n",
    "* price per 100 ml\n",
    "* popularity and worldwide availability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
